{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYT6vYKO2P1P25Mh+YP9L9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivianatuarez/tarea-redes-neuronales-grupo1/blob/main/02_experimentacion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 02 - Experimentación Comparativa\n",
        "## Actividad 3: Redes Neuronales desde Cero\n",
        "### Proyecto 5 - Clasificación de Intenciones en Chatbot de Servicio al Cliente\n",
        "\n",
        "En este notebook realizamos todas las comparaciones solicitadas:\n",
        "- 3+ arquitecturas diferentes\n",
        "- 3 funciones de activación (ReLU, Tanh, Sigmoid)\n",
        "- Múltiples learning rates\n",
        "- Comparación con baseline (regresión logística)\n",
        "- Gráficas y tablas automáticas\n"
      ],
      "metadata": {
        "id": "2fmYnPVa1KGa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-h1l8zu0247",
        "outputId": "25496046-0d7f-4218-ecd7-f10880de38f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Montar Drive (solo la primera vez)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cambiar al directorio del proyecto\n",
        "%cd '/content/drive/MyDrive/tarea-redes-neuronales-grupoX'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytNbF8YN1UPX",
        "outputId": "0e1df705-8d70-445f-991c-9f293fcac350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/tarea-redes-neuronales-grupoX'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Para que las gráficas se vean bonitas\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")"
      ],
      "metadata": {
        "id": "DDkWE96r1XkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cargar datos y preprocesamiento (reutilizamos lo del notebook 01)"
      ],
      "metadata": {
        "id": "NSlpan5v1cKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data/intent_data.csv')\n",
        "\n",
        "# Ampliamos un poco el dataset para que los experimentos sean más realistas\n",
        "extra_texts = [\n",
        "    \"quiero devolver el producto\", \"necesito factura\", \"olvidé mi contraseña\",\n",
        "    \"cómo hago el seguimiento\", \"mi pedido está retrasado\", \"quiero hablar con un agente\",\n",
        "    \"gracias por la ayuda\", \"hasta luego\", \"no funciona el enlace\", \"error en el pago\"\n",
        "]\n",
        "extra_labels = [\n",
        "    'reclamo', 'consultar_precio', 'saludo', 'estado_envio',\n",
        "    'estado_envio', 'saludo', 'saludo', 'saludo', 'reclamo', 'reclamo'\n",
        "]\n",
        "\n",
        "df_extra = pd.DataFrame({'text': extra_texts, 'label': extra_labels})\n",
        "df = pd.concat([df, df_extra], ignore_index=True)\n",
        "df.to_csv('data/intent_data.csv', index=False)\n",
        "\n",
        "print(f\"Total de ejemplos: {len(df)}\")\n",
        "print(f\"Clases: {df['label'].unique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "S6DTXG-41aX9",
        "outputId": "486f90d6-1418-4835-e80e-0583984af168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/intent_data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3896442140.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/intent_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Ampliamos un poco el dataset para que los experimentos sean más realistas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m extra_texts = [\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"quiero devolver el producto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"necesito factura\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"olvidé mi contraseña\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/intent_data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag of Words (mismo código del notebook anterior)\n",
        "from collections import Counter\n",
        "\n",
        "def create_vocabulary(texts, max_vocab=500):\n",
        "    words = ' '.join(texts).lower().split()\n",
        "    most_common = Counter(words).most_common(max_vocab)\n",
        "    vocab = {word: idx+1 for idx, (word, _) in enumerate(most_common)}\n",
        "    vocab['<UNK>'] = 0\n",
        "    return vocab\n",
        "\n",
        "def text_to_bow(text, vocab):\n",
        "    vec = np.zeros(len(vocab))\n",
        "    for word in text.lower().split():\n",
        "        vec[vocab.get(word, 0)] += 1\n",
        "    return vec\n",
        "\n",
        "vocab = create_vocabulary(df['text'])\n",
        "X = np.array([text_to_bow(t, vocab) for t in df['text']])\n",
        "labels = pd.Categorical(df['label']).codes\n",
        "num_classes = len(set(labels))\n",
        "y = np.eye(num_classes)[labels]\n",
        "\n",
        "print(f\"Vocabulario: {len(vocab)} palabras\")\n",
        "print(f\"X shape: {X.shape}, y shape: {y.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "8_vQ9CTF1il4",
        "outputId": "f4c1b2bd-bbac-478e-a842-a60e70647820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3860149529.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext_to_bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clase de la Red Neuronal (la copiamos completa del notebook 01)"
      ],
      "metadata": {
        "id": "2U_o4Rln1oMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, layers, activation='relu', seed=42):\n",
        "        np.random.seed(seed)\n",
        "        self.layers = layers\n",
        "        self.activation = activation\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "\n",
        "        for i in range(1, len(layers)):\n",
        "            if activation in ['sigmoid', 'tanh']:\n",
        "                limit = np.sqrt(6 / (layers[i-1] + layers[i]))\n",
        "                W = np.random.uniform(-limit, limit, (layers[i-1], layers[i]))\n",
        "            else:\n",
        "                std = np.sqrt(2 / layers[i-1])\n",
        "                W = np.random.randn(layers[i-1], layers[i]) * std\n",
        "            b = np.zeros((1, layers[i]))\n",
        "            self.weights.append(W)\n",
        "            self.biases.append(b)\n",
        "\n",
        "    def _activate(self, z, derivative=False):\n",
        "        if self.activation == 'sigmoid':\n",
        "            sig = 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
        "            return sig if not derivative else sig * (1 - sig)\n",
        "        elif self.activation == 'tanh':\n",
        "            return np.tanh(z) if not derivative else 1 - z**2\n",
        "        elif self.activation == 'relu':\n",
        "            return np.maximum(0, z) if not derivative else (z > 0).astype(float)\n",
        "\n",
        "    def forward(self, X):\n",
        "        a = X\n",
        "        self.activations = [X]\n",
        "\n",
        "        for i in range(len(self.layers) - 2):\n",
        "            z = a @ self.weights[i] + self.biases[i]\n",
        "            a = self._activate(z)\n",
        "            self.activations.append(a)\n",
        "\n",
        "        z_out = a @ self.weights[-1] + self.biases[-1]\n",
        "        exp_scores = np.exp(z_out - np.max(z_out, axis=1, keepdims=True))\n",
        "        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "        self.activations.append(probs)\n",
        "        return probs\n",
        "\n",
        "    def backward(self, X, y, output):\n",
        "        m = X.shape[0]\n",
        "        delta = output - y\n",
        "        deltas = [delta]\n",
        "\n",
        "        for i in reversed(range(len(self.layers) - 2)):\n",
        "            delta = (delta @ self.weights[i+1].T) * self._activate(self.activations[i+1], derivative=True)\n",
        "            deltas.append(delta)\n",
        "        deltas.reverse()\n",
        "\n",
        "        dW = [self.activations[i].T @ deltas[i] / m for i in range(len(self.weights))]\n",
        "        db = [np.sum(deltas[i], axis=0, keepdims=True) / m for i in range(len(self.biases))]\n",
        "\n",
        "        return dW, db\n",
        "\n",
        "    def train(self, X, y, epochs=1500, lr=0.01, verbose=False):\n",
        "        losses, accs = [], []\n",
        "        for epoch in range(epochs):\n",
        "            output = self.forward(X)\n",
        "            loss = -np.mean(np.sum(y * np.log(output + 1e-15), axis=1))\n",
        "            acc = np.mean(np.argmax(output, axis=1) == np.argmax(y, axis=1))\n",
        "            losses.append(loss)\n",
        "            accs.append(acc)\n",
        "\n",
        "            dW, db = self.backward(X, y, output)\n",
        "            for i in range(len(self.weights)):\n",
        "                self.weights[i] -= lr * dW[i]\n",
        "                self.biases[i] -= lr * db[i]\n",
        "\n",
        "            if verbose and epoch % 300 == 0:\n",
        "                print(f\"Epoch {epoch:4d} → Loss: {loss:.4f} | Acc: {acc:.4f}\")\n",
        "        return losses, accs"
      ],
      "metadata": {
        "id": "ahrC5g4_1rQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experimentos Masivos (esto es lo que vale puntos!)"
      ],
      "metadata": {
        "id": "BdwIvCUH1wKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos las configuraciones a probar\n",
        "arquitecturas = [\n",
        "    [X.shape[1], 64, 32, num_classes],        # Pequeña\n",
        "    [X.shape[1], 128, 64, num_classes],       # Mediana (mejor en práctica)\n",
        "    [X.shape[1], 256, 128, 64, num_classes],  # Profunda\n",
        "    [X.shape[1], 512, 256, 128, 64, num_classes]  # Muy profunda (bonus)\n",
        "]\n",
        "\n",
        "activaciones = ['relu', 'tanh', 'sigmoid']\n",
        "learning_rates = [0.01, 0.05, 0.1, 0.5]\n",
        "\n",
        "resultados = []\n",
        "\n",
        "print(\"Iniciando experimentos masivos... (puede tardar 3-5 minutos)\\n\")\n",
        "for arch in arquitecturas:\n",
        "    for act in activaciones:\n",
        "        for lr in learning_rates:\n",
        "            print(f\"Probando → {arch} | {act} | lr={lr}\")\n",
        "            model = NeuralNetwork(arch, activation=act, seed=42)\n",
        "            losses, accs = model.train(X, y, epochs=1500, lr=lr, verbose=False)\n",
        "            final_acc = accs[-1]\n",
        "            resultados.append({\n",
        "                'arquitectura': f\"{arch[1:-1]}\",  # sin input/output\n",
        "                'neuronas_totales': sum(arch[1:-1]),\n",
        "                'capas_ocultas': len(arch)-2,\n",
        "                'activacion': act,\n",
        "                'learning_rate': lr,\n",
        "                'accuracy_final': round(final_acc, 4),\n",
        "                'loss_final': round(losses[-1], 4)\n",
        "            })\n",
        "\n",
        "# Guardamos todo\n",
        "df_resultados = pd.DataFrame(resultados)\n",
        "df_resultados = df_resultados.sort_values('accuracy_final', ascending=False)\n",
        "df_resultados.to_csv('results/performance_comparison.csv', index=False)\n",
        "df_resultados.head(15)"
      ],
      "metadata": {
        "id": "pR5hQq3G1y5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfica 1: Mejor combinación\n",
        "plt.figure(figsize=(12, 6))\n",
        "top = df_resultados.head(10)\n",
        "plt.barh(range(len(top)-1, -1, -1), top['accuracy_final'])\n",
        "plt.yticks(range(len(top)), [f\"{row['activacion']}-lr{row['learning_rate']}-{row['capas_ocultas']}capas\" for _, row in top.iterrows()])\n",
        "plt.xlabel('Accuracy Final')\n",
        "plt.title('Top 10 Mejores Configuraciones')\n",
        "plt.xlim(0.7, 1.0)\n",
        "plt.tight_layout()\n",
        "plt.savefig('results/top10_configuraciones.png', dpi=200)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "75EIRAaz13E8",
        "outputId": "6fba0a7a-6d93-4102-bf97-7f4ca1d0f5f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_resultados' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-461651228.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Gráfica 1: Mejor combinación\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_resultados\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy_final'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mf\"{row['activacion']}-lr{row['learning_rate']}-{row['capas_ocultas']}capas\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_resultados' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfica 2: Comparación por función de activación\n",
        "plt.figure(figsize=(10, 6))\n",
        "for act in activaciones:\n",
        "    subset = df_resultados[df_resultados['activacion'] == act]\n",
        "    plt.scatter(subset['learning_rate'], subset['accuracy_final'], label=act, s=80, alpha=0.7)\n",
        "plt.xlabel('Learning Rate')\n",
        "plt.ylabel('Accuracy Final')\n",
        "plt.title('Rendimiento por Función de Activación')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.savefig('results/comparacion_activaciones.png', dpi=200)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FTgCv8it16TI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline: Regresión Logística (desde cero también!)"
      ],
      "metadata": {
        "id": "A-KrXniF178y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegressionScratch:\n",
        "    def __init__(self, lr=0.01, epochs=2000):\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.W = np.zeros((X.shape[1], y.shape[1]))\n",
        "        self.b = np.zeros((1, y.shape[1]))\n",
        "\n",
        "        for _ in range(self.epochs):\n",
        "            z = X @ self.W + self.b\n",
        "            a = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "            a = a / np.sum(a, axis=1, keepdims=True)\n",
        "            self.W -= self.lr * (X.T @ (a - y)) / len(X)\n",
        "            self.b -= self.lr * np.sum(a - y, axis=0, keepdims=True) / len(X)\n",
        "\n",
        "    def predict(self, X):\n",
        "        z = X @ self.W + self.b\n",
        "        a = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "        return a / np.sum(a, axis=1, keepdims=True)\n",
        "\n",
        "logreg = LogisticRegressionScratch(lr=0.1, epochs=3000)\n",
        "logreg.fit(X, y)\n",
        "pred = logreg.predict(X)\n",
        "acc_logreg = np.mean(np.argmax(pred, axis=1) == np.argmax(y, axis=1))\n",
        "print(f\"Accuracy Regresión Logística (baseline): {acc_logreg:.4f}\")"
      ],
      "metadata": {
        "id": "FPePZMgb19vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultado final del experimento"
      ],
      "metadata": {
        "id": "0jDq6kI42DPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mejor = df_resultados.iloc[0]\n",
        "print(f\"GANADOR del experimento:\")\n",
        "print(f\"Arquitectura: {mejor['arquitectura']}\")\n",
        "print(f\"Activación: {mejor['activacion'].upper()}\")\n",
        "print(f\"Learning rate: {mejor['learning_rate']}\")\n",
        "print(f\"Accuracy alcanzada: {mejor['accuracy_final']*100:.2f}%\")\n",
        "print(f\"vs Baseline (LogReg): {acc_logreg*100:.2f}% → ¡Mejora de +{(mejor['accuracy_final']-acc_logreg)*100:.2f} puntos!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "E6uZ0Bey2FCz",
        "outputId": "2780b23e-d9c1-40d1-f367-20a9f1161f3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_resultados' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2578052484.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmejor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_resultados\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"GANADOR del experimento:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Arquitectura: {mejor['arquitectura']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Activación: {mejor['activacion'].upper()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Learning rate: {mejor['learning_rate']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_resultados' is not defined"
          ]
        }
      ]
    }
  ]
}